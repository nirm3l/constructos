# Runtime profile (optional: auto|base|ubuntu-gpu|macos-m4|windows-desktop)
DEPLOY_TARGET=auto

# Ollama runtime mode (optional: auto|docker|docker-gpu|host|none)
# auto       -> try docker-gpu, then host, then docker (macOS profile uses host)
# docker     -> force Ollama as docker service (CPU)
# docker-gpu -> prefer docker GPU mode (falls back to host/docker if unavailable)
# host       -> force host Ollama at http://host.docker.internal:11434
# none       -> disable Ollama service
DEPLOY_OLLAMA_MODE=auto

# Required GHCR image tag
IMAGE_TAG=main

# Required licensing token issued by Constructos control-plane
# If install.sh is run with ACTIVATION_CODE, this is populated automatically.
LICENSE_SERVER_TOKEN=replace-with-license-server-token

# Optional GitHub token for Codex GitHub MCP integration in task-app.
# GITHUB_PAT=ghp_your_token_here

# Optional Codex host mappings for task-app container
# CODEX_CONFIG_FILE defaults to ./codex.config.toml when not set.
# CODEX_AUTH_FILE defaults to ${HOME}/.codex/auth.json when not set.
# CODEX_CONFIG_FILE=./codex.config.toml
# CODEX_AUTH_FILE=/home/your-user/.codex/auth.json
